{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00c497d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from matplotlib import pyplot as plt\n",
    "import text_hammer as th"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df6009f",
   "metadata": {},
   "source": [
    "## Data loading and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d78297",
   "metadata": {},
   "source": [
    "#### Data reading\n",
    "The data comes with the columns 'keyword' and 'location'. However, a quick look into the data shows that there is not much relationship between 'keyword', 'location' and whether or not a disaster happens. Therefore, we will just consider the 'text' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67780aef",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  Our Deeds are the Reason of this #earthquake M...       1\n",
       "1             Forest fire near La Ronge Sask. Canada       1\n",
       "2  All residents asked to 'shelter in place' are ...       1\n",
       "3  13,000 people receive #wildfires evacuation or...       1\n",
       "4  Just got sent this photo from Ruby #Alaska as ...       1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "df_pred:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0                 Just happened a terrible car crash\n",
       "1  Heard about #earthquake is different cities, s...\n",
       "2  there is a forest fire at spot pond, geese are...\n",
       "3           Apocalypse lighting. #Spokane #wildfires\n",
       "4      Typhoon Soudelor kills 28 in China and Taiwan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train = pd.read_csv('data/train.csv', usecols=['text','target'])\n",
    "df_pred = pd.read_csv('data/test.csv', usecols=['text'])\n",
    "\n",
    "print('df_train:')\n",
    "display(df_train.head(5))\n",
    "print()\n",
    "print('df_pred:')\n",
    "display(df_pred.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a0c883",
   "metadata": {},
   "source": [
    "#### Data cleanup\n",
    "We clean the text by the following steps:\n",
    "1. lowercase all characters, remove '\\\\' and replace '_' by ' '\n",
    "2. remove emails, urls\n",
    "3. remove special characters, accented characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "165fb48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up_text(col_data):\n",
    "    col_data = col_data.apply(lambda x: str(x).lower().replace('\\\\','')).replace('_',' ')   \n",
    "    col_data = col_data.apply(lambda x: th.remove_emails(x))\n",
    "    col_data = col_data.apply(lambda x: th.remove_urls(x))\n",
    "    col_data = col_data.apply(lambda x: th.remove_special_chars(x))\n",
    "    col_data = col_data.apply(lambda x: th.remove_accented_chars(x)) \n",
    "    return col_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2325f2c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>our deeds are the reason of this earthquake ma...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>all residents asked to shelter in place are be...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13000 people receive wildfires evacuation orde...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>just got sent this photo from ruby alaska as s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  our deeds are the reason of this earthquake ma...       1\n",
       "1              forest fire near la ronge sask canada       1\n",
       "2  all residents asked to shelter in place are be...       1\n",
       "3  13000 people receive wildfires evacuation orde...       1\n",
       "4  just got sent this photo from ruby alaska as s...       1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "df_pred:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>heard about earthquake is different cities sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>there is a forest fire at spot pond geese are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>apocalypse lighting spokane wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>typhoon soudelor kills 28 in china and taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0                 just happened a terrible car crash\n",
       "1  heard about earthquake is different cities sta...\n",
       "2  there is a forest fire at spot pond geese are ...\n",
       "3              apocalypse lighting spokane wildfires\n",
       "4      typhoon soudelor kills 28 in china and taiwan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train['text'] = clean_up_text(df_train['text'])\n",
    "df_pred['text'] = clean_up_text(df_pred['text'])\n",
    "\n",
    "print('df_train:')\n",
    "display(df_train.head(5))\n",
    "print()\n",
    "print('df_pred:')\n",
    "display(df_pred.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aaeafb7",
   "metadata": {},
   "source": [
    "#### Match data length for each label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e337da07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original train data:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    4342\n",
       "1    3271\n",
       "Name: target, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed train data:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    3271\n",
       "1    3271\n",
       "Name: target, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print('Original train data:')\n",
    "display(df_train['target'].value_counts())\n",
    "print()\n",
    "\n",
    "# collect all negative and all positive data\n",
    "df_n = df_train[df_train['target']==0]\n",
    "df_p = df_train[df_train['target']==1]\n",
    "\n",
    "# randomly select from df_n the same number of samples as df_p\n",
    "df_n = df_n.sample(df_p.shape[0])\n",
    "\n",
    "# concatenate df_n and df_p together to get a new df_train\n",
    "df_train = pd.concat([df_n, df_p])\n",
    "\n",
    "print('Processed train data:')\n",
    "display(df_train['target'].value_counts())\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3b88ba",
   "metadata": {},
   "source": [
    "#### Seperate train, validation and test data_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f167d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train data = 5233\n",
      "Length of val data = 654\n",
      "Length of test data = 655\n"
     ]
    }
   ],
   "source": [
    "# split train data\n",
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "df_train['text'],df_train['target'],test_size=0.2, stratify=df_train['target'])\n",
    "# split validation data and test data\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_val, y_val, test_size=0.5, stratify=y_val)\n",
    "\n",
    "print('Length of train data =', len(x_train))\n",
    "print('Length of val data =', len(x_val))\n",
    "print('Length of test data =', len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f57fa78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part of x_train:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5031    lolly_knickers its a mudslide its like chewing...\n",
       "4591    judson1360 xtra1360 oline and pass rush rest o...\n",
       "3122    seriously look like a get electrocuted after i...\n",
       "2866    tips so that finding the customers ego drought...\n",
       "2691    ignition knock detonation sensorsenso fits 010...\n",
       "Name: text, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corresponding labels:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5031    1\n",
       "4591    0\n",
       "3122    0\n",
       "2866    0\n",
       "2691    1\n",
       "Name: target, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "\n",
      "Part of x_val:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4619    follownflnews michael floyds hand injury shoul...\n",
       "7432    small bag from the bottom the wounded hero sha...\n",
       "4062    climate consequences us forest service says sp...\n",
       "5708    video were picking up bodies from water rescue...\n",
       "5344    if she dont know bout that pandemonium album s...\n",
       "Name: text, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corresponding labels:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4619    0\n",
       "7432    0\n",
       "4062    1\n",
       "5708    1\n",
       "5344    0\n",
       "Name: target, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "\n",
      "Part of x_test:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2101    i tell my cousins i dont wanna hang out and th...\n",
       "4113      adriasimon_ hailstorm day 2 round2 yyc yycstorm\n",
       "3929    1 pair new 27w 4 round led work driving flood ...\n",
       "2552    just made anthonys bed considering i destroy i...\n",
       "3851    my gang walking round with them brown flames a...\n",
       "Name: text, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corresponding labels:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2101    0\n",
       "4113    1\n",
       "3929    0\n",
       "2552    1\n",
       "3851    0\n",
       "Name: target, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show part of data:\n",
    "print('Part of x_train:')\n",
    "display(x_train.head(5))\n",
    "print('Corresponding labels:')\n",
    "display(y_train.head(5))\n",
    "print('-------------------------')\n",
    "print()\n",
    "print('Part of x_val:')\n",
    "display(x_val.head(5))\n",
    "print('Corresponding labels:')\n",
    "display(y_val.head(5))\n",
    "print('-------------------------')\n",
    "print()\n",
    "print('Part of x_test:')\n",
    "display(x_test.head(5))\n",
    "print('Corresponding labels:')\n",
    "display(y_test.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2880a42f",
   "metadata": {},
   "source": [
    "## Model setup and machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2691e2d",
   "metadata": {},
   "source": [
    "#### Model setup\n",
    "We choose Bert model as out natural language embedding tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc134570",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the Bert preprocessor and encoder\n",
    "preprocessor = hub.KerasLayer('https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3')\n",
    "encoder = hub.KerasLayer('https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "278a4d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " text (InputLayer)              [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " keras_layer (KerasLayer)       {'input_mask': (Non  0           ['text[0][0]']                   \n",
      "                                e, 128),                                                          \n",
      "                                 'input_type_ids':                                                \n",
      "                                (None, 128),                                                      \n",
      "                                 'input_word_ids':                                                \n",
      "                                (None, 128)}                                                      \n",
      "                                                                                                  \n",
      " keras_layer_1 (KerasLayer)     {'default': (None,   109482241   ['keras_layer[0][0]',            \n",
      "                                768),                             'keras_layer[0][1]',            \n",
      "                                 'encoder_outputs':               'keras_layer[0][2]']            \n",
      "                                 [(None, 128, 768),                                               \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768)],                                               \n",
      "                                 'pooled_output': (                                               \n",
      "                                None, 768),                                                       \n",
      "                                 'sequence_output':                                               \n",
      "                                 (None, 128, 768)}                                                \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 768)          0           ['keras_layer_1[0][13]']         \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 128)          98432       ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 128)          0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 32)           4128        ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 1)            33          ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109,584,834\n",
      "Trainable params: 102,593\n",
      "Non-trainable params: 109,482,241\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model definition\n",
    "\n",
    "# Bert layers\n",
    "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "encoder_input = preprocessor(text_input)\n",
    "embeddings = encoder(encoder_input)\n",
    "\n",
    "# neural network layers\n",
    "layer = tf.keras.layers.Dropout(0.1, name='dropout_1')(embeddings['pooled_output'])\n",
    "layer = tf.keras.layers.Dense(128, activation='relu', name='dense_1')(layer)\n",
    "layer = tf.keras.layers.Dropout(0.1, name='dropout_2')(layer)\n",
    "layer = tf.keras.layers.Dense(32, activation='relu', name='dense_2')(layer)\n",
    "output = tf.keras.layers.Dense(1, activation='sigmoid', name='output')(layer)\n",
    "\n",
    "# Construct the model\n",
    "model = tf.keras.Model(inputs=[text_input], outputs=[output])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab3665db",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "    tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "    tf.keras.metrics.Precision(name='precision'),\n",
    "    tf.keras.metrics.Recall(name='recall')\n",
    "]\n",
    "\n",
    "model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'binary_crossentropy',\n",
    "    metrics = METRICS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "838c6a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "164/164 [==============================] - 57s 226ms/step - loss: 0.6267 - accuracy: 0.6526 - precision: 0.6575 - recall: 0.6374 - val_loss: 0.5206 - val_accuracy: 0.7615 - val_precision: 0.7841 - val_recall: 0.7217\n",
      "Epoch 2/20\n",
      "164/164 [==============================] - 35s 214ms/step - loss: 0.5607 - accuracy: 0.7179 - precision: 0.7378 - recall: 0.6763 - val_loss: 0.5009 - val_accuracy: 0.7554 - val_precision: 0.7263 - val_recall: 0.8196\n",
      "Epoch 3/20\n",
      "164/164 [==============================] - 35s 215ms/step - loss: 0.5387 - accuracy: 0.7334 - precision: 0.7531 - recall: 0.6947 - val_loss: 0.4743 - val_accuracy: 0.7920 - val_precision: 0.8524 - val_recall: 0.7064\n",
      "Epoch 4/20\n",
      "164/164 [==============================] - 35s 215ms/step - loss: 0.5357 - accuracy: 0.7357 - precision: 0.7630 - recall: 0.6840 - val_loss: 0.4745 - val_accuracy: 0.7813 - val_precision: 0.7659 - val_recall: 0.8104\n",
      "Epoch 5/20\n",
      "164/164 [==============================] - 35s 213ms/step - loss: 0.5208 - accuracy: 0.7455 - precision: 0.7742 - recall: 0.6932 - val_loss: 0.4815 - val_accuracy: 0.7905 - val_precision: 0.7714 - val_recall: 0.8257\n",
      "Epoch 6/20\n",
      "164/164 [==============================] - 35s 215ms/step - loss: 0.5212 - accuracy: 0.7483 - precision: 0.7814 - recall: 0.6897 - val_loss: 0.4438 - val_accuracy: 0.8119 - val_precision: 0.8566 - val_recall: 0.7492\n",
      "Epoch 7/20\n",
      "164/164 [==============================] - 35s 214ms/step - loss: 0.5194 - accuracy: 0.7439 - precision: 0.7720 - recall: 0.6924 - val_loss: 0.5048 - val_accuracy: 0.7569 - val_precision: 0.9242 - val_recall: 0.5596\n",
      "Epoch 8/20\n",
      "164/164 [==============================] - 35s 212ms/step - loss: 0.5104 - accuracy: 0.7527 - precision: 0.7984 - recall: 0.6763 - val_loss: 0.4571 - val_accuracy: 0.7813 - val_precision: 0.7722 - val_recall: 0.7982\n",
      "Epoch 9/20\n",
      "164/164 [==============================] - 35s 214ms/step - loss: 0.5134 - accuracy: 0.7485 - precision: 0.7815 - recall: 0.6901 - val_loss: 0.4602 - val_accuracy: 0.7997 - val_precision: 0.9083 - val_recall: 0.6667\n",
      "Epoch 10/20\n",
      "164/164 [==============================] - 35s 214ms/step - loss: 0.5130 - accuracy: 0.7478 - precision: 0.7871 - recall: 0.6794 - val_loss: 0.4470 - val_accuracy: 0.8012 - val_precision: 0.8863 - val_recall: 0.6911\n",
      "Epoch 11/20\n",
      "164/164 [==============================] - 36s 217ms/step - loss: 0.5151 - accuracy: 0.7457 - precision: 0.7803 - recall: 0.6840 - val_loss: 0.4414 - val_accuracy: 0.8043 - val_precision: 0.8645 - val_recall: 0.7217\n",
      "Epoch 12/20\n",
      "164/164 [==============================] - 35s 212ms/step - loss: 0.5022 - accuracy: 0.7596 - precision: 0.7915 - recall: 0.7050 - val_loss: 0.4397 - val_accuracy: 0.8104 - val_precision: 0.8919 - val_recall: 0.7064\n",
      "Epoch 13/20\n",
      "164/164 [==============================] - 35s 215ms/step - loss: 0.5025 - accuracy: 0.7546 - precision: 0.7953 - recall: 0.6859 - val_loss: 0.4588 - val_accuracy: 0.8135 - val_precision: 0.9084 - val_recall: 0.6972\n",
      "Epoch 14/20\n",
      "164/164 [==============================] - 34s 209ms/step - loss: 0.4976 - accuracy: 0.7629 - precision: 0.8044 - recall: 0.6947 - val_loss: 0.4693 - val_accuracy: 0.7783 - val_precision: 0.9213 - val_recall: 0.6086\n",
      "Epoch 15/20\n",
      "164/164 [==============================] - 35s 214ms/step - loss: 0.5003 - accuracy: 0.7586 - precision: 0.7977 - recall: 0.6932 - val_loss: 0.5016 - val_accuracy: 0.7538 - val_precision: 0.9278 - val_recall: 0.5505\n",
      "Epoch 16/20\n",
      "164/164 [==============================] - 35s 215ms/step - loss: 0.5011 - accuracy: 0.7533 - precision: 0.7888 - recall: 0.6920 - val_loss: 0.4471 - val_accuracy: 0.8089 - val_precision: 0.8607 - val_recall: 0.7370\n",
      "Epoch 17/20\n",
      "164/164 [==============================] - 35s 217ms/step - loss: 0.4989 - accuracy: 0.7621 - precision: 0.8019 - recall: 0.6962 - val_loss: 0.4314 - val_accuracy: 0.8119 - val_precision: 0.8643 - val_recall: 0.7401\n",
      "Epoch 18/20\n",
      "164/164 [==============================] - 36s 220ms/step - loss: 0.4937 - accuracy: 0.7617 - precision: 0.8012 - recall: 0.6962 - val_loss: 0.4734 - val_accuracy: 0.7645 - val_precision: 0.9261 - val_recall: 0.5749\n",
      "Epoch 19/20\n",
      "164/164 [==============================] - 36s 217ms/step - loss: 0.4957 - accuracy: 0.7577 - precision: 0.8042 - recall: 0.6813 - val_loss: 0.4360 - val_accuracy: 0.7982 - val_precision: 0.7964 - val_recall: 0.8012\n",
      "Epoch 20/20\n",
      "164/164 [==============================] - 35s 216ms/step - loss: 0.5013 - accuracy: 0.7556 - precision: 0.7881 - recall: 0.6993 - val_loss: 0.4321 - val_accuracy: 0.8119 - val_precision: 0.8446 - val_recall: 0.7645\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2287c3fcc10>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=32,\n",
    "    epochs=20,\n",
    "    validation_data=(x_val, y_val),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358859a6",
   "metadata": {},
   "source": [
    "#### Run data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f6d6761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 4s 183ms/step - loss: 0.5200 - accuracy: 0.7466 - precision: 0.7906 - recall: 0.6697\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b66163",
   "metadata": {},
   "source": [
    "#### Model save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17d0a98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('NLP_disaster_tweets_v1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347c060b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
